#!/usr/bin/env python3
"""
Script cháº¡y crawler vá»›i cÃ¡c tÃ¹y chá»n khÃ¡c nhau
"""

import asyncio
import argparse
import sys
import time
from .index import NhatotRealEstateCrawler


def print_banner():
    """In banner chÃ o má»«ng"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   ğŸ  NHATOT CRAWLER ğŸ                      â•‘
â•‘              Crawler Báº¥t Äá»™ng Sáº£n Viá»‡t Nam                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


async def run_crawler_with_options(
    browserless_url: str,
    max_pages: int,
    output_file: str = None
):
    """
    Cháº¡y crawler vá»›i cÃ¡c tÃ¹y chá»n Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    
    Args:
        browserless_url: URL cá»§a browserless service
        max_pages: Sá»‘ trang tá»‘i Ä‘a Ä‘á»ƒ crawl
        output_file: TÃªn file output (optional)
    """
    print(f"âš™ï¸  Cáº¥u hÃ¬nh:")
    print(f"   ğŸ“ Browserless URL: {browserless_url}")
    print(f"   ğŸ“„ Sá»‘ trang tá»‘i Ä‘a: {max_pages}")
    if output_file:
        print(f"   ğŸ“ File output: {output_file}")
    print("-" * 60)
    
    # Khá»Ÿi táº¡o crawler
    crawler = NhatotRealEstateCrawler(browserless_url, max_pages)
    
    # TÃ¹y chá»‰nh output file náº¿u cÃ³
    if output_file:
        original_save = crawler.save_to_csv
        def custom_save():
            return original_save(output_file)
        crawler.save_to_csv = custom_save
    
    # Cháº¡y crawler
    start_time = time.time()
    success = await crawler.crawl_nhatot_danang()
    end_time = time.time()
    
    print("-" * 60)
    print(f"â±ï¸  Thá»i gian thá»±c hiá»‡n: {end_time - start_time:.2f} giÃ¢y")
    
    return success


def main():
    """HÃ m main vá»›i argument parsing"""
    parser = argparse.ArgumentParser(
        description="Crawler dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n tá»« nhatot.com",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  python run_crawler.py                                    # Cháº¡y vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
  python run_crawler.py --pages 10                        # Crawl 10 trang
  python run_crawler.py --output my_data.csv               # LÆ°u vÃ o file tÃ¹y chá»‰nh
  python run_crawler.py --url ws://remote:3000             # Sá»­ dá»¥ng browserless remote
        """
    )
    
    parser.add_argument(
        "--url", "-u",
        default="ws://localhost:3000",
        help="URL cá»§a browserless service (máº·c Ä‘á»‹nh: ws://localhost:3000)"
    )
    
    parser.add_argument(
        "--pages", "-p",
        type=int,
        default=5,
        help="Sá»‘ trang tá»‘i Ä‘a Ä‘á»ƒ crawl (máº·c Ä‘á»‹nh: 5)"
    )
    
    parser.add_argument(
        "--output", "-o",
        help="TÃªn file CSV output (máº·c Ä‘á»‹nh: auto-generate vá»›i timestamp)"
    )
    
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Cháº¡y á»Ÿ cháº¿ Ä‘á»™ im láº·ng (Ã­t log hÆ¡n)"
    )
    
    args = parser.parse_args()
    
    # Validation
    if args.pages < 1 or args.pages > 50:
        print("âŒ Sá»‘ trang pháº£i tá»« 1-50")
        sys.exit(1)
    
    # In banner náº¿u khÃ´ng á»Ÿ cháº¿ Ä‘á»™ quiet
    if not args.quiet:
        print_banner()
    
    # Cháº¡y crawler
    try:
        success = asyncio.run(run_crawler_with_options(
            browserless_url=args.url,
            max_pages=args.pages,
            output_file=args.output
        ))
        
        if success:
            print("ğŸ‰ Crawler hoÃ n thÃ nh thÃ nh cÃ´ng!")
            sys.exit(0)
        else:
            print("âŒ Crawler tháº¥t báº¡i!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸  Crawler bá»‹ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng")
        sys.exit(130)
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng mong Ä‘á»£i: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 